#!/usr/bin/env python3
"""Enhanced Generation 1 Demo - Advanced MAKE IT WORK implementation.

This demo showcases enhanced Generation 1 functionality with:
- Improved error handling and resilience
- Enhanced metrics collection and reporting
- Better configuration management
- Advanced training monitoring
- Comprehensive progress tracking
"""

import sys
import time
import json
from pathlib import Path

# Add src to path for local imports
sys.path.insert(0, str(Path(__file__).parent / "src"))

from gaudi3_scale import GaudiTrainer, GaudiAccelerator, get_logger
from gaudi3_scale.validation import DataValidator
from gaudi3_scale.config_validation import validate_training_config


def create_enhanced_training_config():
    """Create enhanced training configuration with validation."""
    config = {
        "model_name": "enhanced-llama-demo",
        "model_config": {
            "model_type": "causal_lm",
            "hidden_size": 4096,
            "num_layers": 32,
            "num_heads": 32,
            "vocab_size": 32000,
            "max_seq_length": 2048,
            "dtype": "bfloat16"
        },
        "training_config": {
            "learning_rate": 6e-4,
            "batch_size": 8,
            "gradient_accumulation_steps": 4,
            "num_epochs": 3,
            "warmup_steps": 100,
            "weight_decay": 0.01,
            "gradient_clip_val": 1.0,
            "save_every_n_steps": 50,
            "eval_every_n_steps": 100
        },
        "data_config": {
            "dataset_name": "synthetic_text",
            "num_samples": 1000,
            "sequence_length": 512,
            "validation_split": 0.1
        },
        "optimization_config": {
            "optimizer": "AdamW",
            "scheduler": "cosine",
            "precision": "bf16-mixed",
            "compile_model": True,
            "use_flash_attention": True
        },
        "logging_config": {
            "log_level": "INFO",
            "log_every_n_steps": 10,
            "save_logs": True,
            "tensorboard_logging": True,
            "wandb_logging": False
        },
        "output_config": {
            "output_dir": "enhanced_gen1_output",
            "save_checkpoints": True,
            "checkpoint_every_n_epochs": 1,
            "keep_best_checkpoint": True,
            "save_final_model": True
        }
    }
    
    # Validate configuration
    validation_result = validate_training_config(config)
    if not validation_result.is_valid:
        raise ValueError(f"Configuration validation failed: {validation_result.errors}")
    
    return config


def setup_enhanced_monitoring():
    """Setup enhanced monitoring and metrics collection."""
    logger = get_logger(__name__)
    logger.info("Setting up enhanced monitoring system")
    
    monitoring_config = {
        "metrics_enabled": True,
        "performance_tracking": True,
        "memory_monitoring": True,
        "throughput_calculation": True,
        "loss_tracking": True,
        "learning_rate_monitoring": True,
        "gradient_norm_tracking": True,
        "checkpoint_management": True
    }
    
    return monitoring_config


def enhanced_data_generation(config):
    """Generate enhanced synthetic training data."""
    logger = get_logger(__name__)
    logger.info("Generating enhanced synthetic training data")
    
    data_config = config["data_config"]
    num_samples = data_config["num_samples"]
    sequence_length = data_config["sequence_length"]
    
    # Simulate more realistic data generation
    training_data = []
    validation_data = []
    
    for i in range(num_samples):
        # Generate synthetic text sequences
        sample = {
            "input_ids": list(range(i % 1000, (i % 1000) + sequence_length)),
            "attention_mask": [1] * sequence_length,
            "labels": list(range((i % 1000) + 1, (i % 1000) + sequence_length + 1))
        }
        
        # Split into training and validation
        if i < int(num_samples * (1 - data_config["validation_split"])):
            training_data.append(sample)
        else:
            validation_data.append(sample)
    
    logger.info(f"Generated {len(training_data)} training samples and {len(validation_data)} validation samples")
    
    return training_data, validation_data


def run_enhanced_training_loop(trainer, config, training_data, validation_data):
    """Run enhanced training loop with comprehensive monitoring."""
    logger = get_logger(__name__)
    logger.info("Starting enhanced training loop")
    
    training_config = config["training_config"]
    num_epochs = training_config["num_epochs"]
    batch_size = training_config["batch_size"]
    
    # Training metrics storage
    training_metrics = {
        "epochs": [],
        "losses": [],
        "learning_rates": [],
        "throughput": [],
        "memory_usage": [],
        "training_time": []
    }
    
    # Start training
    # Call callbacks instead of direct trainer methods
    for callback in trainer.callbacks:
        callback.on_train_start(trainer)
    total_start_time = time.time()
    
    for epoch in range(num_epochs):
        epoch_start_time = time.time()
        logger.info(f"Starting epoch {epoch + 1}/{num_epochs}")
        
        # Call callbacks for epoch start
        for callback in trainer.callbacks:
            callback.on_epoch_start(trainer, epoch)
        
        # Simulate batch processing
        num_batches = len(training_data) // batch_size
        epoch_loss = 0.0
        
        for batch_idx in range(num_batches):
            batch_start_time = time.time()
            # Call callbacks for batch start
            for callback in trainer.callbacks:
                callback.on_batch_start(trainer, batch_idx)
            
            # Simulate training step
            batch_data = training_data[batch_idx * batch_size:(batch_idx + 1) * batch_size]
            
            # Simulate forward pass and loss calculation
            simulated_loss = 2.5 - (epoch * 0.3) - (batch_idx * 0.001) + (abs(hash(str(batch_idx))) % 100) / 1000.0
            epoch_loss += simulated_loss
            
            # Simulate memory usage
            memory_usage = 12.5 + (epoch * 0.1) + (abs(hash(str(batch_idx))) % 50) / 100.0
            
            # Calculate throughput
            batch_time = time.time() - batch_start_time
            throughput = batch_size / batch_time if batch_time > 0 else 0
            
            # Log batch metrics
            batch_logs = {
                "loss": simulated_loss,
                "memory_usage": memory_usage,
                "throughput": throughput,
                "learning_rate": training_config["learning_rate"] * (1 - epoch * 0.1)
            }
            
            # Call callbacks for batch end
            for callback in trainer.callbacks:
                callback.on_batch_end(trainer, batch_idx, batch_logs)
            
            # Log progress every 10 batches
            if batch_idx % 10 == 0:
                logger.info(f"Epoch {epoch + 1}, Batch {batch_idx}: loss={simulated_loss:.4f}, "
                           f"throughput={throughput:.2f} samples/s, memory={memory_usage:.1f}GB")
            
            # Simulate checkpoint saving
            if batch_idx % training_config.get("save_every_n_steps", 50) == 0:
                # Create checkpoint data
                checkpoint_data = {
                    "epoch": epoch,
                    "batch_idx": batch_idx,
                    "loss": simulated_loss,
                    "model_state": f"checkpoint_epoch_{epoch}_batch_{batch_idx}.pt"
                }
                # Simulate checkpoint saving
                checkpoint_file = trainer.output_dir / f"checkpoint_epoch_{epoch}.json"
                with open(checkpoint_file, 'w') as f:
                    json.dump(checkpoint_data, f, indent=2)
        
        # Calculate epoch metrics
        epoch_time = time.time() - epoch_start_time
        avg_epoch_loss = epoch_loss / num_batches
        epoch_throughput = (num_batches * batch_size) / epoch_time
        
        # Store epoch metrics
        training_metrics["epochs"].append(epoch + 1)
        training_metrics["losses"].append(avg_epoch_loss)
        training_metrics["learning_rates"].append(training_config["learning_rate"] * (1 - epoch * 0.1))
        training_metrics["throughput"].append(epoch_throughput)
        training_metrics["memory_usage"].append(memory_usage)
        training_metrics["training_time"].append(epoch_time)
        
        # Run validation
        if validation_data and epoch % 1 == 0:  # Validate every epoch
            val_loss = run_validation(validation_data, batch_size)
            logger.info(f"Validation loss: {val_loss:.4f}")
        
        epoch_logs = {
            "epoch": epoch + 1,
            "train_loss": avg_epoch_loss,
            "val_loss": val_loss if 'val_loss' in locals() else None,
            "learning_rate": training_config["learning_rate"] * (1 - epoch * 0.1),
            "epoch_time": epoch_time,
            "throughput": epoch_throughput
        }
        
        # Call callbacks for epoch end
        for callback in trainer.callbacks:
            callback.on_epoch_end(trainer, epoch, epoch_logs)
        
        logger.info(f"Epoch {epoch + 1} completed: loss={avg_epoch_loss:.4f}, "
                   f"time={epoch_time:.2f}s, throughput={epoch_throughput:.2f} samples/s")
    
    total_time = time.time() - total_start_time
    # Call callbacks for training end
    for callback in trainer.callbacks:
        callback.on_train_end(trainer)
    
    logger.info(f"Training completed in {total_time:.2f} seconds")
    
    return training_metrics


def run_validation(validation_data, batch_size):
    """Run validation loop."""
    logger = get_logger(__name__)
    logger.info("Running validation")
    
    val_loss = 0.0
    num_batches = len(validation_data) // batch_size
    
    for batch_idx in range(num_batches):
        # Simulate validation loss (slightly lower than training)
        simulated_val_loss = 2.0 - (batch_idx * 0.002) + (abs(hash(str(batch_idx))) % 80) / 1000.0
        val_loss += simulated_val_loss
    
    return val_loss / num_batches if num_batches > 0 else 0.0


def save_enhanced_results(config, training_metrics, output_dir):
    """Save comprehensive training results."""
    logger = get_logger(__name__)
    logger.info(f"Saving enhanced results to {output_dir}")
    
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)
    
    # Save training metrics
    metrics_file = output_path / "enhanced_training_metrics.json"
    with open(metrics_file, 'w') as f:
        json.dump(training_metrics, f, indent=2)
    
    # Save training configuration
    config_file = output_path / "enhanced_training_config.json"
    with open(config_file, 'w') as f:
        json.dump(config, f, indent=2)
    
    # Generate training summary
    summary = {
        "model_name": config["model_name"],
        "total_epochs": len(training_metrics["epochs"]),
        "final_loss": training_metrics["losses"][-1] if training_metrics["losses"] else None,
        "avg_throughput": sum(training_metrics["throughput"]) / len(training_metrics["throughput"]) if training_metrics["throughput"] else 0,
        "total_training_time": sum(training_metrics["training_time"]) if training_metrics["training_time"] else 0,
        "peak_memory_usage": max(training_metrics["memory_usage"]) if training_metrics["memory_usage"] else 0,
        "status": "completed",
        "generation": "Enhanced Generation 1",
        "features": [
            "Advanced configuration validation",
            "Comprehensive metrics collection",
            "Enhanced error handling",
            "Real-time monitoring",
            "Checkpoint management",
            "Validation tracking"
        ]
    }
    
    summary_file = output_path / "enhanced_training_summary.json"
    with open(summary_file, 'w') as f:
        json.dump(summary, f, indent=2)
    
    logger.info("Enhanced results saved successfully")
    return summary


def main():
    """Main enhanced Generation 1 demonstration."""
    logger = get_logger(__name__)
    logger.info("=" * 60)
    logger.info("ðŸš€ TERRAGON SDLC - Enhanced Generation 1 Demo")
    logger.info("Enhanced MAKE IT WORK implementation")
    logger.info("=" * 60)
    
    try:
        # Create enhanced configuration
        logger.info("ðŸ“‹ Creating enhanced training configuration...")
        config = create_enhanced_training_config()
        
        # Setup monitoring
        logger.info("ðŸ“Š Setting up enhanced monitoring...")
        monitoring_config = setup_enhanced_monitoring()
        
        # Initialize enhanced trainer
        logger.info("ðŸŽ¯ Initializing enhanced trainer...")
        trainer = GaudiTrainer(
            model_name=config["model_name"],
            output_dir=config["output_config"]["output_dir"],
            enable_monitoring=True
        )
        
        # Generate enhanced data
        logger.info("ðŸ“ˆ Generating enhanced training data...")
        training_data, validation_data = enhanced_data_generation(config)
        
        # Run enhanced training
        logger.info("ðŸ”¥ Starting enhanced training loop...")
        training_metrics = run_enhanced_training_loop(trainer, config, training_data, validation_data)
        
        # Save enhanced results
        logger.info("ðŸ’¾ Saving enhanced results...")
        summary = save_enhanced_results(config, training_metrics, config["output_config"]["output_dir"])
        
        # Display final results
        logger.info("=" * 60)
        logger.info("âœ… Enhanced Generation 1 Demo Completed Successfully!")
        logger.info("=" * 60)
        logger.info(f"ðŸ“Š Final Results:")
        logger.info(f"   â€¢ Model: {summary['model_name']}")
        logger.info(f"   â€¢ Epochs: {summary['total_epochs']}")
        logger.info(f"   â€¢ Final Loss: {summary['final_loss']:.4f}")
        logger.info(f"   â€¢ Avg Throughput: {summary['avg_throughput']:.2f} samples/s")
        logger.info(f"   â€¢ Training Time: {summary['total_training_time']:.2f}s")
        logger.info(f"   â€¢ Peak Memory: {summary['peak_memory_usage']:.1f}GB")
        logger.info(f"   â€¢ Status: {summary['status']}")
        logger.info("=" * 60)
        
        return True
        
    except Exception as e:
        logger.error(f"Enhanced Generation 1 demo failed: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)